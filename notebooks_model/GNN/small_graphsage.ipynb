{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa852a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, SAGEConv\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import from_scipy_sparse_matrix\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score\n",
    "from scipy.sparse import csr_matrix\n",
    "import joblib\n",
    "\n",
    "import random\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5aa0ebd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# Seeds and Hyperparameters\n",
    "# ====================\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "\n",
    "set_seed()\n",
    "\n",
    "# Hyperparameters\n",
    "k = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e4ebe5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================\n",
    "# LOAD DATA\n",
    "# ====================\n",
    "df = pd.read_csv(\"../../dataset/dataset.csv\")  \n",
    "\n",
    "# 2. Define your feature columns and label\n",
    "features = ['CHF_F30',\n",
    "            'HICHOLRP',\n",
    "            'INCONT',\n",
    "            'BKBONMOM',\n",
    "            'PREG',\n",
    "            'AGE',\n",
    "            'ETHNICNIH',\n",
    "            'F45CALC',\n",
    "            'F60ALCWK',\n",
    "            'F60CALC',]\n",
    "\n",
    "outcome = 'ANYFX'\n",
    "\n",
    "X = df[features].values\n",
    "y = df[outcome].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14c72618",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_idx = np.where(y == 0)[0]\n",
    "class_1_idx = np.where(y == 1)[0]\n",
    "\n",
    "undersample_size = min(len(class_0_idx), len(class_1_idx))\n",
    "\n",
    "undersample_idx_0 = np.random.choice(class_0_idx, undersample_size, replace=False)\n",
    "undersample_idx_1 = np.random.choice(class_1_idx, undersample_size, replace=False)\n",
    "\n",
    "balanced_idx = np.concatenate([undersample_idx_0, undersample_idx_1])\n",
    "\n",
    "X_balanced = X[balanced_idx]\n",
    "y_balanced = y[balanced_idx]\n",
    "\n",
    "# ====================\n",
    "# STRATIFIED SPLIT\n",
    "# ====================\n",
    "splitter = StratifiedShuffleSplit(n_splits=1, test_size=0.4, random_state=42)\n",
    "train_idx, temp_idx = next(splitter.split(X_balanced, y_balanced))\n",
    "\n",
    "X_train, y_train = X_balanced[train_idx], y_balanced[train_idx]\n",
    "X_temp, y_temp = X_balanced[temp_idx], y_balanced[temp_idx]\n",
    "\n",
    "splitter_val = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_idx, test_idx = next(splitter_val.split(X_temp, y_temp))\n",
    "\n",
    "X_val, y_val = X_temp[val_idx], y_temp[val_idx]\n",
    "X_test, y_test = X_temp[test_idx], y_temp[test_idx]\n",
    "\n",
    "# ====================\n",
    "# SCALING\n",
    "# ====================\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_val = scaler.transform(X_val)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# ====================\n",
    "# KNN\n",
    "# ====================\n",
    "def build_knn_graph(X_split, k):\n",
    "    knn_local = NearestNeighbors(n_neighbors=k)\n",
    "    knn_local.fit(X_split)\n",
    "    adj_matrix = knn_local.kneighbors_graph(X_split, mode='connectivity')\n",
    "    edge_index, _ = from_scipy_sparse_matrix(csr_matrix(adj_matrix))\n",
    "    return edge_index\n",
    "\n",
    "knn = NearestNeighbors(n_neighbors=k)\n",
    "knn.fit(X)\n",
    "\n",
    "# ====================\n",
    "# DEFINE MODELS\n",
    "# ====================\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.sage1 = SAGEConv(input_dim, hidden_dim)\n",
    "        self.sage2 = SAGEConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        x = F.relu(self.sage1(x, edge_index))\n",
    "        x = self.sage2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# ====================\n",
    "# EVALUATION FUNCTION\n",
    "# ====================\n",
    "@torch.no_grad()\n",
    "def evaluate(model, X_split, y_split, k=k):\n",
    "    model.eval()\n",
    "    edge_index = build_knn_graph(X_split, k)\n",
    "    data_split = Data(x=torch.tensor(X_split, dtype=torch.float).to(device),\n",
    "                      edge_index=edge_index.to(device))\n",
    "    logits = model(data_split.x, data_split.edge_index)\n",
    "    preds = logits.argmax(dim=1).cpu().numpy()\n",
    "\n",
    "    acc = accuracy_score(y_split, preds)\n",
    "    auc = roc_auc_score(y_split, preds)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_split, preds).ravel()\n",
    "    sensitivity = tp / (tp + fn)\n",
    "    specificity = tn / (tn + fp)\n",
    "    return acc, sensitivity, specificity, auc\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=20, verbose=False, delta=0):\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_auc, model, path):\n",
    "        score = val_auc\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model, path)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(model, path)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, model, path):\n",
    "        torch.save(model.state_dict(), path)\n",
    "        \n",
    "# ====================\n",
    "# TRAINING FUNCTION\n",
    "# ====================\n",
    "def run_training(model_type='gcn'):\n",
    "    if model_type == 'gcn':\n",
    "        model = GCN(input_dim=X.shape[1], hidden_dim=64, output_dim=2).to(device)\n",
    "    elif model_type == 'sage':\n",
    "        model = GraphSAGE(input_dim=X.shape[1], hidden_dim=64, output_dim=2).to(device)\n",
    "    else:\n",
    "        raise ValueError(\"Choose either 'gcn' or 'sage'\")\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, verbose=True)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=30, verbose=True)\n",
    "    save_path = f'saved_models/best_{model_type}_model.pt'\n",
    "\n",
    "    data_train = Data(x=torch.tensor(X_train, dtype=torch.float).to(device),\n",
    "                      edge_index=build_knn_graph(X_train, k).to(device),\n",
    "                      y=torch.tensor(y_train, dtype=torch.long).to(device))\n",
    "    \n",
    "    for epoch in range(1, 501):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data_train.x, data_train.edge_index)\n",
    "        loss = criterion(out, data_train.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if epoch % 5 == 0:\n",
    "            train_acc, _, _, _ = evaluate(model, X_train, y_train, k)\n",
    "            val_acc, val_sens, val_spec, val_auc = evaluate(model, X_val, y_val, k)\n",
    "            print(f'{model_type.upper()} Epoch {epoch:03d} | Loss: {loss:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Val AUC: {val_auc:.4f}')\n",
    "\n",
    "            scheduler.step(val_auc)\n",
    "            early_stopping(val_auc, model, save_path)\n",
    "\n",
    "            if early_stopping.early_stop:\n",
    "                print(\"Early stopping triggered.\")\n",
    "                break\n",
    "\n",
    "    model.load_state_dict(torch.load(save_path))\n",
    "    test_acc, test_sens, test_spec, test_auc = evaluate(model, X_test, y_test, k)\n",
    "    print(f'\\n{model_type.upper()} Test Metrics:')\n",
    "    print(f'Accuracy: {test_acc:.4f}')\n",
    "    print(f'Sensitivity: {test_sens:.4f}')\n",
    "    print(f'Specificity: {test_spec:.4f}')\n",
    "    print(f'AUC: {test_auc:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8250ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN Epoch 005 | Loss: 0.6937 | Train Acc: 0.5377 | Val Acc: 0.5334 | Val AUC: 0.5334\n",
      "GCN Epoch 010 | Loss: 0.6941 | Train Acc: 0.5510 | Val Acc: 0.5438 | Val AUC: 0.5438\n",
      "GCN Epoch 015 | Loss: 0.6849 | Train Acc: 0.5550 | Val Acc: 0.5236 | Val AUC: 0.5236\n",
      "EarlyStopping counter: 1 out of 30\n",
      "GCN Epoch 020 | Loss: 0.6852 | Train Acc: 0.5521 | Val Acc: 0.5207 | Val AUC: 0.5207\n",
      "EarlyStopping counter: 2 out of 30\n",
      "GCN Epoch 025 | Loss: 0.6825 | Train Acc: 0.5659 | Val Acc: 0.5282 | Val AUC: 0.5282\n",
      "EarlyStopping counter: 3 out of 30\n",
      "GCN Epoch 030 | Loss: 0.6817 | Train Acc: 0.5700 | Val Acc: 0.5363 | Val AUC: 0.5363\n",
      "EarlyStopping counter: 4 out of 30\n",
      "GCN Epoch 035 | Loss: 0.6810 | Train Acc: 0.5675 | Val Acc: 0.5282 | Val AUC: 0.5282\n",
      "EarlyStopping counter: 5 out of 30\n",
      "GCN Epoch 040 | Loss: 0.6804 | Train Acc: 0.5675 | Val Acc: 0.5334 | Val AUC: 0.5334\n",
      "EarlyStopping counter: 6 out of 30\n",
      "GCN Epoch 045 | Loss: 0.6800 | Train Acc: 0.5711 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "EarlyStopping counter: 7 out of 30\n",
      "GCN Epoch 050 | Loss: 0.6797 | Train Acc: 0.5707 | Val Acc: 0.5363 | Val AUC: 0.5363\n",
      "EarlyStopping counter: 8 out of 30\n",
      "GCN Epoch 055 | Loss: 0.6794 | Train Acc: 0.5729 | Val Acc: 0.5323 | Val AUC: 0.5323\n",
      "EarlyStopping counter: 9 out of 30\n",
      "GCN Epoch 060 | Loss: 0.6792 | Train Acc: 0.5734 | Val Acc: 0.5300 | Val AUC: 0.5300\n",
      "EarlyStopping counter: 10 out of 30\n",
      "GCN Epoch 065 | Loss: 0.6789 | Train Acc: 0.5719 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "Epoch 00013: reducing learning rate of group 0 to 5.0000e-03.\n",
      "EarlyStopping counter: 11 out of 30\n",
      "GCN Epoch 070 | Loss: 0.6788 | Train Acc: 0.5742 | Val Acc: 0.5363 | Val AUC: 0.5363\n",
      "EarlyStopping counter: 12 out of 30\n",
      "GCN Epoch 075 | Loss: 0.6787 | Train Acc: 0.5736 | Val Acc: 0.5311 | Val AUC: 0.5311\n",
      "EarlyStopping counter: 13 out of 30\n",
      "GCN Epoch 080 | Loss: 0.6786 | Train Acc: 0.5744 | Val Acc: 0.5294 | Val AUC: 0.5294\n",
      "EarlyStopping counter: 14 out of 30\n",
      "GCN Epoch 085 | Loss: 0.6785 | Train Acc: 0.5725 | Val Acc: 0.5351 | Val AUC: 0.5351\n",
      "EarlyStopping counter: 15 out of 30\n",
      "GCN Epoch 090 | Loss: 0.6784 | Train Acc: 0.5736 | Val Acc: 0.5311 | Val AUC: 0.5311\n",
      "EarlyStopping counter: 16 out of 30\n",
      "GCN Epoch 095 | Loss: 0.6783 | Train Acc: 0.5721 | Val Acc: 0.5328 | Val AUC: 0.5328\n",
      "EarlyStopping counter: 17 out of 30\n",
      "GCN Epoch 100 | Loss: 0.6782 | Train Acc: 0.5711 | Val Acc: 0.5305 | Val AUC: 0.5305\n",
      "EarlyStopping counter: 18 out of 30\n",
      "GCN Epoch 105 | Loss: 0.6781 | Train Acc: 0.5717 | Val Acc: 0.5300 | Val AUC: 0.5300\n",
      "EarlyStopping counter: 19 out of 30\n",
      "GCN Epoch 110 | Loss: 0.6780 | Train Acc: 0.5721 | Val Acc: 0.5305 | Val AUC: 0.5305\n",
      "EarlyStopping counter: 20 out of 30\n",
      "GCN Epoch 115 | Loss: 0.6779 | Train Acc: 0.5727 | Val Acc: 0.5323 | Val AUC: 0.5323\n",
      "EarlyStopping counter: 21 out of 30\n",
      "GCN Epoch 120 | Loss: 0.6778 | Train Acc: 0.5721 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "Epoch 00024: reducing learning rate of group 0 to 2.5000e-03.\n",
      "EarlyStopping counter: 22 out of 30\n",
      "GCN Epoch 125 | Loss: 0.6777 | Train Acc: 0.5725 | Val Acc: 0.5357 | Val AUC: 0.5357\n",
      "EarlyStopping counter: 23 out of 30\n",
      "GCN Epoch 130 | Loss: 0.6777 | Train Acc: 0.5719 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "EarlyStopping counter: 24 out of 30\n",
      "GCN Epoch 135 | Loss: 0.6776 | Train Acc: 0.5721 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "EarlyStopping counter: 25 out of 30\n",
      "GCN Epoch 140 | Loss: 0.6776 | Train Acc: 0.5723 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 26 out of 30\n",
      "GCN Epoch 145 | Loss: 0.6775 | Train Acc: 0.5717 | Val Acc: 0.5351 | Val AUC: 0.5351\n",
      "EarlyStopping counter: 27 out of 30\n",
      "GCN Epoch 150 | Loss: 0.6775 | Train Acc: 0.5715 | Val Acc: 0.5357 | Val AUC: 0.5357\n",
      "EarlyStopping counter: 28 out of 30\n",
      "GCN Epoch 155 | Loss: 0.6775 | Train Acc: 0.5717 | Val Acc: 0.5351 | Val AUC: 0.5351\n",
      "EarlyStopping counter: 29 out of 30\n",
      "GCN Epoch 160 | Loss: 0.6774 | Train Acc: 0.5713 | Val Acc: 0.5357 | Val AUC: 0.5357\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping triggered.\n",
      "\n",
      "GCN Test Metrics:\n",
      "Accuracy: 0.5406\n",
      "Sensitivity: 0.4954\n",
      "Specificity: 0.5857\n",
      "AUC: 0.5406\n"
     ]
    }
   ],
   "source": [
    "run_training('gcn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "25f2276b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAGE Epoch 005 | Loss: 0.6951 | Train Acc: 0.5504 | Val Acc: 0.5207 | Val AUC: 0.5207\n",
      "SAGE Epoch 010 | Loss: 0.6839 | Train Acc: 0.5586 | Val Acc: 0.5392 | Val AUC: 0.5392\n",
      "SAGE Epoch 015 | Loss: 0.6826 | Train Acc: 0.5608 | Val Acc: 0.5300 | Val AUC: 0.5300\n",
      "EarlyStopping counter: 1 out of 30\n",
      "SAGE Epoch 020 | Loss: 0.6784 | Train Acc: 0.5700 | Val Acc: 0.5288 | Val AUC: 0.5288\n",
      "EarlyStopping counter: 2 out of 30\n",
      "SAGE Epoch 025 | Loss: 0.6774 | Train Acc: 0.5677 | Val Acc: 0.5426 | Val AUC: 0.5426\n",
      "SAGE Epoch 030 | Loss: 0.6760 | Train Acc: 0.5692 | Val Acc: 0.5282 | Val AUC: 0.5282\n",
      "EarlyStopping counter: 1 out of 30\n",
      "SAGE Epoch 035 | Loss: 0.6750 | Train Acc: 0.5706 | Val Acc: 0.5305 | Val AUC: 0.5305\n",
      "EarlyStopping counter: 2 out of 30\n",
      "SAGE Epoch 040 | Loss: 0.6740 | Train Acc: 0.5767 | Val Acc: 0.5271 | Val AUC: 0.5271\n",
      "EarlyStopping counter: 3 out of 30\n",
      "SAGE Epoch 045 | Loss: 0.6730 | Train Acc: 0.5757 | Val Acc: 0.5253 | Val AUC: 0.5253\n",
      "EarlyStopping counter: 4 out of 30\n",
      "SAGE Epoch 050 | Loss: 0.6719 | Train Acc: 0.5796 | Val Acc: 0.5300 | Val AUC: 0.5300\n",
      "EarlyStopping counter: 5 out of 30\n",
      "SAGE Epoch 055 | Loss: 0.6709 | Train Acc: 0.5767 | Val Acc: 0.5328 | Val AUC: 0.5328\n",
      "EarlyStopping counter: 6 out of 30\n",
      "SAGE Epoch 060 | Loss: 0.6698 | Train Acc: 0.5821 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "EarlyStopping counter: 7 out of 30\n",
      "SAGE Epoch 065 | Loss: 0.6686 | Train Acc: 0.5840 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 8 out of 30\n",
      "SAGE Epoch 070 | Loss: 0.6674 | Train Acc: 0.5836 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 9 out of 30\n",
      "SAGE Epoch 075 | Loss: 0.6661 | Train Acc: 0.5849 | Val Acc: 0.5305 | Val AUC: 0.5305\n",
      "EarlyStopping counter: 10 out of 30\n",
      "SAGE Epoch 080 | Loss: 0.6648 | Train Acc: 0.5890 | Val Acc: 0.5305 | Val AUC: 0.5305\n",
      "Epoch 00016: reducing learning rate of group 0 to 5.0000e-03.\n",
      "EarlyStopping counter: 11 out of 30\n",
      "SAGE Epoch 085 | Loss: 0.6639 | Train Acc: 0.5911 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 12 out of 30\n",
      "SAGE Epoch 090 | Loss: 0.6631 | Train Acc: 0.5878 | Val Acc: 0.5311 | Val AUC: 0.5311\n",
      "EarlyStopping counter: 13 out of 30\n",
      "SAGE Epoch 095 | Loss: 0.6624 | Train Acc: 0.5913 | Val Acc: 0.5328 | Val AUC: 0.5328\n",
      "EarlyStopping counter: 14 out of 30\n",
      "SAGE Epoch 100 | Loss: 0.6616 | Train Acc: 0.5928 | Val Acc: 0.5294 | Val AUC: 0.5294\n",
      "EarlyStopping counter: 15 out of 30\n",
      "SAGE Epoch 105 | Loss: 0.6608 | Train Acc: 0.5951 | Val Acc: 0.5311 | Val AUC: 0.5311\n",
      "EarlyStopping counter: 16 out of 30\n",
      "SAGE Epoch 110 | Loss: 0.6599 | Train Acc: 0.5963 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 17 out of 30\n",
      "SAGE Epoch 115 | Loss: 0.6591 | Train Acc: 0.5969 | Val Acc: 0.5340 | Val AUC: 0.5340\n",
      "EarlyStopping counter: 18 out of 30\n",
      "SAGE Epoch 120 | Loss: 0.6583 | Train Acc: 0.5995 | Val Acc: 0.5328 | Val AUC: 0.5328\n",
      "EarlyStopping counter: 19 out of 30\n",
      "SAGE Epoch 125 | Loss: 0.6574 | Train Acc: 0.5974 | Val Acc: 0.5351 | Val AUC: 0.5351\n",
      "EarlyStopping counter: 20 out of 30\n",
      "SAGE Epoch 130 | Loss: 0.6565 | Train Acc: 0.5974 | Val Acc: 0.5357 | Val AUC: 0.5357\n",
      "EarlyStopping counter: 21 out of 30\n",
      "SAGE Epoch 135 | Loss: 0.6556 | Train Acc: 0.6003 | Val Acc: 0.5374 | Val AUC: 0.5374\n",
      "Epoch 00027: reducing learning rate of group 0 to 2.5000e-03.\n",
      "EarlyStopping counter: 22 out of 30\n",
      "SAGE Epoch 140 | Loss: 0.6550 | Train Acc: 0.5986 | Val Acc: 0.5357 | Val AUC: 0.5357\n",
      "EarlyStopping counter: 23 out of 30\n",
      "SAGE Epoch 145 | Loss: 0.6546 | Train Acc: 0.6011 | Val Acc: 0.5346 | Val AUC: 0.5346\n",
      "EarlyStopping counter: 24 out of 30\n",
      "SAGE Epoch 150 | Loss: 0.6541 | Train Acc: 0.6007 | Val Acc: 0.5369 | Val AUC: 0.5369\n",
      "EarlyStopping counter: 25 out of 30\n",
      "SAGE Epoch 155 | Loss: 0.6536 | Train Acc: 0.6011 | Val Acc: 0.5363 | Val AUC: 0.5363\n",
      "EarlyStopping counter: 26 out of 30\n",
      "SAGE Epoch 160 | Loss: 0.6532 | Train Acc: 0.6015 | Val Acc: 0.5363 | Val AUC: 0.5363\n",
      "EarlyStopping counter: 27 out of 30\n",
      "SAGE Epoch 165 | Loss: 0.6527 | Train Acc: 0.6038 | Val Acc: 0.5369 | Val AUC: 0.5369\n",
      "EarlyStopping counter: 28 out of 30\n",
      "SAGE Epoch 170 | Loss: 0.6522 | Train Acc: 0.6041 | Val Acc: 0.5369 | Val AUC: 0.5369\n",
      "EarlyStopping counter: 29 out of 30\n",
      "SAGE Epoch 175 | Loss: 0.6518 | Train Acc: 0.6036 | Val Acc: 0.5386 | Val AUC: 0.5386\n",
      "EarlyStopping counter: 30 out of 30\n",
      "Early stopping triggered.\n",
      "\n",
      "SAGE Test Metrics:\n",
      "Accuracy: 0.5435\n",
      "Sensitivity: 0.5668\n",
      "Specificity: 0.5201\n",
      "AUC: 0.5435\n"
     ]
    }
   ],
   "source": [
    "run_training('sage')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "henrygnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
