{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a797a92-03ab-4605-ba5a-c965f049c2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import tqdm.notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ecfceed-ccda-42c6-a5a8-7078d944f1d2",
   "metadata": {},
   "source": [
    "### Load the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b47f9afa-ca89-4b54-b684-7479f2bb29a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dataset.csv  'Variable Names (1).xlsx'\n"
     ]
    }
   ],
   "source": [
    "!ls dataset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d4bec852-3cbf-4b2c-be49-239360eb0845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>CTFLAG</th>\n",
       "      <th>ANYFX</th>\n",
       "      <th>FRAX_SCORE</th>\n",
       "      <th>PARKINS</th>\n",
       "      <th>RHEUMAT</th>\n",
       "      <th>OSTEOPOR</th>\n",
       "      <th>ARTHRIT</th>\n",
       "      <th>CANC_F30</th>\n",
       "      <th>CATARACT</th>\n",
       "      <th>...</th>\n",
       "      <th>F60VITA</th>\n",
       "      <th>TEXPWK</th>\n",
       "      <th>WALKSPD</th>\n",
       "      <th>BKBONE</th>\n",
       "      <th>BKHIP</th>\n",
       "      <th>BKBACK</th>\n",
       "      <th>BKLARM</th>\n",
       "      <th>SMOKING</th>\n",
       "      <th>YEARS_MENOPAUSE</th>\n",
       "      <th>DUR_MENA_MENO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>131073</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>975.84083</td>\n",
       "      <td>2.50000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>262147</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>848.40762</td>\n",
       "      <td>26.83333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131075</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>629.72861</td>\n",
       "      <td>21.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>262149</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>339.14853</td>\n",
       "      <td>32.83333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>262150</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.73</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1574.51101</td>\n",
       "      <td>21.83333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>-30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74769</th>\n",
       "      <td>262130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>668.50414</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74770</th>\n",
       "      <td>131066</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>334.67271</td>\n",
       "      <td>7.50000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-46.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74771</th>\n",
       "      <td>262131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1195.77043</td>\n",
       "      <td>17.08333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74772</th>\n",
       "      <td>131068</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1169.27512</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>-45.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74773</th>\n",
       "      <td>262142</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>589.26054</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>-37.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>74204 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           ID  CTFLAG  ANYFX  FRAX_SCORE  PARKINS  RHEUMAT  OSTEOPOR  ARTHRIT  \\\n",
       "0      131073       1      0        6.14      0.0      0.0       0.0      0.0   \n",
       "1      262147       1      0        8.05      0.0      8.0       0.0      1.0   \n",
       "2      131075       0      0       12.88      0.0      8.0       0.0      1.0   \n",
       "3      262149       0      0        8.78      0.0      8.0       0.0      1.0   \n",
       "4      262150       1      1        1.73      0.0      0.0       0.0      0.0   \n",
       "...       ...     ...    ...         ...      ...      ...       ...      ...   \n",
       "74769  262130       1      0        3.07      0.0      0.0       0.0      0.0   \n",
       "74770  131066       1      0        3.94      0.0      0.0       0.0      0.0   \n",
       "74771  262131       0      0        4.45      0.0      0.0       0.0      0.0   \n",
       "74772  131068       1      0        8.54      0.0      0.0       0.0      0.0   \n",
       "74773  262142       1      0        8.11      0.0      8.0       0.0      1.0   \n",
       "\n",
       "       CANC_F30  CATARACT  ...     F60VITA    TEXPWK  WALKSPD  BKBONE  BKHIP  \\\n",
       "0           0.0       0.0  ...   975.84083   2.50000      3.0     1.0    0.0   \n",
       "1           0.0       0.0  ...   848.40762  26.83333      3.0     0.0    0.0   \n",
       "2           0.0       1.0  ...   629.72861  21.00000      3.0     1.0    0.0   \n",
       "3           0.0       0.0  ...   339.14853  32.83333      4.0     0.0    0.0   \n",
       "4           0.0       0.0  ...  1574.51101  21.83333      3.0     0.0    0.0   \n",
       "...         ...       ...  ...         ...       ...      ...     ...    ...   \n",
       "74769       0.0       0.0  ...   668.50414   0.00000      3.0     1.0    0.0   \n",
       "74770       0.0       0.0  ...   334.67271   7.50000      3.0     0.0    0.0   \n",
       "74771       0.0       0.0  ...  1195.77043  17.08333      3.0     0.0    0.0   \n",
       "74772       0.0       0.0  ...  1169.27512   0.00000      9.0     1.0    0.0   \n",
       "74773       0.0       1.0  ...   589.26054   0.00000      9.0     0.0    0.0   \n",
       "\n",
       "       BKBACK  BKLARM  SMOKING  YEARS_MENOPAUSE  DUR_MENA_MENO  \n",
       "0         0.0     1.0      1.0             10.0          -45.0  \n",
       "1         0.0     0.0      1.0             13.0          -44.0  \n",
       "2         0.0     0.0      1.0             11.0          -45.0  \n",
       "3         0.0     0.0      1.0             15.0          -45.0  \n",
       "4         0.0     0.0      0.0             19.0          -30.0  \n",
       "...       ...     ...      ...              ...            ...  \n",
       "74769     0.0     0.0      0.0              2.0          -46.0  \n",
       "74770     0.0     0.0      0.0              7.0          -46.0  \n",
       "74771     0.0     0.0      1.0              1.0          -47.0  \n",
       "74772     0.0     0.0      0.0             13.0          -45.0  \n",
       "74773     0.0     0.0      1.0             24.0          -37.0  \n",
       "\n",
       "[74204 rows x 67 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/dataset.csv\", index_col = [0])\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "612288fe-8259-47ca-b7d8-834e930aea89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (31470, 67)\n"
     ]
    }
   ],
   "source": [
    "#extract cohort, labels, patid\n",
    "df = df[df[\"CTFLAG\"] == 1]\n",
    "\n",
    "#do not drop frax score yet\n",
    "labels = df[\"ANYFX\"]\n",
    "dataset = df.drop(columns = [\"ANYFX\", \"CTFLAG\", \"ID\"]) \n",
    "\n",
    "print(\"Dataset Shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a34e07bf-5470-485d-a1b6-f0cff41d2987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANYFX\n",
      "0    27835\n",
      "1     3635\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(labels.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15728ab1-4a1c-4b7b-babc-998cbae4fbb5",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1e59b17d-946b-46e4-a13d-80799760dbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "def FRAX_maximize_youden_j(y_true: pd.Series, y_prob: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Finds the optimal threshold that maximizes Youden’s J Statistic (TPR - FPR).\n",
    "\n",
    "    :param y_true: Pandas Series of true binary labels (0 or 1).\n",
    "    :param y_prob: Pandas Series of predicted probabilities.\n",
    "    :return: The optimal threshold for classification.\n",
    "    \"\"\"\n",
    "    # Compute ROC curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_true, y_prob)\n",
    "    \n",
    "    # Compute Youden’s J statistic\n",
    "    j_scores = tpr - fpr\n",
    "\n",
    "    # Find the optimal threshold (maximum J score)\n",
    "    best_threshold = thresholds[np.argmax(j_scores)]\n",
    "\n",
    "    print(f\"Optimal Threshold (Max Youden's J): {best_threshold:.4f}\")\n",
    "\n",
    "    return best_threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3a58f285-d177-4be2-8375-60cc43a54a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "def weighted_downsample(X: pd.DataFrame, \n",
    "                        y: pd.Series, \n",
    "                        feature_list: list = [\"ETHNICNIH\", \"RACENIH\"],\n",
    "                        weights_dict: dict = None, \n",
    "                        frac: float = 0.5, \n",
    "                        random_state: int = 42):\n",
    "\n",
    "    valid_features = [f for f in feature_list if f in X.columns]\n",
    "    if not valid_features:\n",
    "        raise ValueError(\"None of the specified features exist in X.\")\n",
    "\n",
    "    #no weights_dict is provided\n",
    "    if weights_dict is None:\n",
    "        weights_dict = {feature: 1 / len(valid_features) for feature in valid_features}\n",
    "\n",
    "    total_weight = sum(weights_dict.values())\n",
    "    normalized_weights = {k: v / total_weight for k, v in weights_dict.items() if k in valid_features}\n",
    "    sampling_weights = X[valid_features].mul(normalized_weights).sum(axis=1)\n",
    "    sampling_weights = np.maximum(sampling_weights, 1e-10)  # Avoid zero probability\n",
    "    sampling_weights /= sampling_weights.sum()\n",
    "    downsampled_indices = (\n",
    "        pd.concat([X, y], axis=1) \n",
    "        .groupby(y.name, group_keys=False)  \n",
    "        .apply(lambda group: group.sample(frac=frac, weights=sampling_weights.loc[group.index], random_state=random_state))\n",
    "        .index\n",
    "    )\n",
    "\n",
    "    X_downsampled = X.loc[downsampled_indices]\n",
    "    y_downsampled = y.loc[downsampled_indices]\n",
    "\n",
    "    return X_downsampled, y_downsampled\n",
    "\n",
    "\n",
    "def weighted_downsample_LABELS(df, labels, target_ratio=0.5, random_state=42):\n",
    "    \"\"\"\n",
    "    Performs weighted downsampling to balance classes in the dataset.\n",
    "\n",
    "    :param df: DataFrame with features.\n",
    "    :param labels: Series with target labels.\n",
    "    :param target_ratio: Desired ratio of the minority class.\n",
    "    :param random_state: Random seed for reproducibility.\n",
    "    :return: Downsampled features (X) and labels (y).\n",
    "    \"\"\"\n",
    "    # Combine features and labels into one DataFrame\n",
    "    df['label'] = labels\n",
    "    \n",
    "    # Identify majority and minority classes\n",
    "    class_counts = df['label'].value_counts()\n",
    "    min_class = class_counts.idxmin()\n",
    "    maj_class = class_counts.idxmax()\n",
    "\n",
    "    # Compute the target number of samples for the majority class\n",
    "    n_min = class_counts[min_class]\n",
    "    n_maj = int(n_min / target_ratio - n_min)\n",
    "\n",
    "    # Downsample the majority class\n",
    "    df_minority = df[df['label'] == min_class]\n",
    "    df_majority_downsampled = resample(df[df['label'] == maj_class], \n",
    "                                       replace=False, \n",
    "                                       n_samples=n_maj, \n",
    "                                       random_state=random_state)\n",
    "\n",
    "    # Combine the balanced dataset\n",
    "    df_balanced = pd.concat([df_minority, df_majority_downsampled])\n",
    "\n",
    "    # Separate features and labels again\n",
    "    y_balanced = df_balanced['label']\n",
    "    X_balanced = df_balanced.drop(columns=['label'])\n",
    "\n",
    "    return X_balanced, y_balanced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "35ced703-36ad-496e-8bf6-413ad1b33c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score, f1_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def evaluate_model(y_true, y_pred, y_prob=None, descr = None):\n",
    "    \"\"\"\n",
    "    Computes and prints standard classification metrics: Accuracy, AUC, Precision, Recall, and F1-score.\n",
    "\n",
    "    :param y_true: List or array of true labels (0 or 1).\n",
    "    :param y_pred: List or array of predicted labels (0 or 1).\n",
    "    :param y_prob: List or array of predicted probabilities (optional, needed for AUC).\n",
    "    :return: Dictionary containing Accuracy, AUC, Precision, Recall, and F1-score.\n",
    "    \"\"\"\n",
    "    metrics = {\n",
    "        \"Accuracy\": accuracy_score(y_true, y_pred),\n",
    "        \"Precision\": precision_score(y_true, y_pred, zero_division=0),\n",
    "        \"Recall\": recall_score(y_true, y_pred, zero_division=0),\n",
    "        \"F1-score\": f1_score(y_true, y_pred, zero_division=0),\n",
    "        \"AUC\": roc_auc_score(y_true, y_prob) \n",
    "    }\n",
    "\n",
    "    # Print metrics\n",
    "    if descr:\n",
    "        print(descr)\n",
    "    for key, value in metrics.items():\n",
    "        print(f\"\\t{key}: {value:.4f}\" if value is not None else f\"{key}: N/A (Only one class present)\")\n",
    "\n",
    "    return metrics\n",
    "\n",
    "    \n",
    "    #extract featuresd\n",
    "    y_pred = model.predict(X_train_balanced)\n",
    "    y_prob = model.predict_proba(X_train_balanced)[:, 1]\n",
    "\n",
    "def eval_run(model, x, y, descr = None):\n",
    "    y_pred = model.predict(x)\n",
    "    y_prob = model.predict_proba(x)[:, 1]\n",
    "    evaluate_model(y, y_pred, y_prob, descr = descr)\n",
    "\n",
    "def eval_frax(frax_scores, labels, descr = None, threshold = None):\n",
    "    if threshold:\n",
    "        pass\n",
    "    else:\n",
    "        threshold = FRAX_maximize_youden_j(labels, frax_scores)\n",
    "    y_pred = (frax_scores >= threshold).astype(int)\n",
    "    evaluate_model(labels, y_pred, frax_scores, descr = descr)\n",
    "    return threshold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9d697bdc-5518-4c65-85ff-75d18437f6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_cv_avail = True\n",
    "\n",
    "import scipy\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': scipy.stats.randint(100, 500),\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': scipy.stats.randint(2, 20),\n",
    "    'min_samples_leaf': scipy.stats.randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f999eb55-b7c7-483b-a4c6-10de4bdf0fed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5--------------------------\n",
      "Training Fold Label Distr: {0: 6785, 1: 2908}\n",
      "Best Parameters: {'max_depth': 30, 'max_features': 'log2', 'min_samples_leaf': 2, 'min_samples_split': 7, 'n_estimators': 153}\n",
      "\tAccuracy: 0.9782\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.9274\n",
      "\tF1-score: 0.9624\n",
      "\tAUC: 1.0000\n",
      "Optimal Threshold (Max Youden's J): 6.9800\n",
      "FRAX Train Metrics:\n",
      "\tAccuracy: 0.5927\n",
      "\tPrecision: 0.3637\n",
      "\tRecall: 0.4773\n",
      "\tF1-score: 0.4128\n",
      "\tAUC: 0.5836\n",
      "Test Split:\n",
      "\tAccuracy: 0.8834\n",
      "\tPrecision: 0.3704\n",
      "\tRecall: 0.0138\n",
      "\tF1-score: 0.0265\n",
      "\tAUC: 0.5878\n",
      "FRAX Test Metrics:\n",
      "\tAccuracy: 0.6214\n",
      "\tPrecision: 0.1409\n",
      "\tRecall: 0.4470\n",
      "\tF1-score: 0.2143\n",
      "\tAUC: 0.5695\n",
      "Test Fold Label Distr: {0: 5567, 1: 727}\n",
      "\n",
      "\n",
      "Fold 2/5--------------------------\n",
      "Training Fold Label Distr: {0: 6785, 1: 2908}\n",
      "Best Parameters: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 17, 'n_estimators': 336}\n",
      "\tAccuracy: 0.7531\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.1771\n",
      "\tF1-score: 0.3009\n",
      "\tAUC: 0.9951\n",
      "Optimal Threshold (Max Youden's J): 7.0100\n",
      "FRAX Train Metrics:\n",
      "\tAccuracy: 0.5948\n",
      "\tPrecision: 0.3640\n",
      "\tRecall: 0.4694\n",
      "\tF1-score: 0.4100\n",
      "\tAUC: 0.5836\n",
      "Test Split:\n",
      "\tAccuracy: 0.8840\n",
      "\tPrecision: 0.2000\n",
      "\tRecall: 0.0014\n",
      "\tF1-score: 0.0027\n",
      "\tAUC: 0.6161\n",
      "FRAX Test Metrics:\n",
      "\tAccuracy: 0.6119\n",
      "\tPrecision: 0.1398\n",
      "\tRecall: 0.4580\n",
      "\tF1-score: 0.2142\n",
      "\tAUC: 0.5753\n",
      "Test Fold Label Distr: {0: 5567, 1: 727}\n",
      "\n",
      "\n",
      "Fold 3/5--------------------------\n",
      "Training Fold Label Distr: {0: 6785, 1: 2908}\n",
      "Best Parameters: {'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 445}\n",
      "\tAccuracy: 0.9581\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.8604\n",
      "\tF1-score: 0.9250\n",
      "\tAUC: 1.0000\n",
      "Optimal Threshold (Max Youden's J): 5.5600\n",
      "FRAX Train Metrics:\n",
      "\tAccuracy: 0.5037\n",
      "\tPrecision: 0.3364\n",
      "\tRecall: 0.6730\n",
      "\tF1-score: 0.4486\n",
      "\tAUC: 0.5751\n",
      "Test Split:\n",
      "\tAccuracy: 0.8823\n",
      "\tPrecision: 0.1818\n",
      "\tRecall: 0.0055\n",
      "\tF1-score: 0.0107\n",
      "\tAUC: 0.6077\n",
      "FRAX Test Metrics:\n",
      "\tAccuracy: 0.4611\n",
      "\tPrecision: 0.1320\n",
      "\tRecall: 0.6575\n",
      "\tF1-score: 0.2199\n",
      "\tAUC: 0.5859\n",
      "Test Fold Label Distr: {0: 5567, 1: 727}\n",
      "\n",
      "\n",
      "Fold 4/5--------------------------\n",
      "Training Fold Label Distr: {0: 6785, 1: 2908}\n",
      "Best Parameters: {'max_depth': None, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 108}\n",
      "\tAccuracy: 0.9907\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.9691\n",
      "\tF1-score: 0.9843\n",
      "\tAUC: 1.0000\n",
      "Optimal Threshold (Max Youden's J): 6.9800\n",
      "FRAX Train Metrics:\n",
      "\tAccuracy: 0.5920\n",
      "\tPrecision: 0.3616\n",
      "\tRecall: 0.4704\n",
      "\tF1-score: 0.4089\n",
      "\tAUC: 0.5775\n",
      "Test Split:\n",
      "\tAccuracy: 0.8802\n",
      "\tPrecision: 0.2545\n",
      "\tRecall: 0.0193\n",
      "\tF1-score: 0.0358\n",
      "\tAUC: 0.5842\n",
      "FRAX Test Metrics:\n",
      "\tAccuracy: 0.6192\n",
      "\tPrecision: 0.1462\n",
      "\tRecall: 0.4746\n",
      "\tF1-score: 0.2235\n",
      "\tAUC: 0.5923\n",
      "Test Fold Label Distr: {0: 5567, 1: 727}\n",
      "\n",
      "\n",
      "Fold 5/5--------------------------\n",
      "Training Fold Label Distr: {0: 6785, 1: 2908}\n",
      "Best Parameters: {'max_depth': 20, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 5, 'n_estimators': 149}\n",
      "\tAccuracy: 0.9704\n",
      "\tPrecision: 1.0000\n",
      "\tRecall: 0.9013\n",
      "\tF1-score: 0.9481\n",
      "\tAUC: 1.0000\n",
      "Optimal Threshold (Max Youden's J): 7.7900\n",
      "FRAX Train Metrics:\n",
      "\tAccuracy: 0.6291\n",
      "\tPrecision: 0.3784\n",
      "\tRecall: 0.3676\n",
      "\tF1-score: 0.3729\n",
      "\tAUC: 0.5799\n",
      "Test Split:\n",
      "\tAccuracy: 0.8820\n",
      "\tPrecision: 0.3095\n",
      "\tRecall: 0.0179\n",
      "\tF1-score: 0.0338\n",
      "\tAUC: 0.5945\n",
      "FRAX Test Metrics:\n",
      "\tAccuracy: 0.6873\n",
      "\tPrecision: 0.1488\n",
      "\tRecall: 0.3618\n",
      "\tF1-score: 0.2109\n",
      "\tAUC: 0.5733\n",
      "Test Fold Label Distr: {0: 5567, 1: 727}\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "n_splits = 5\n",
    "random_state = 45\n",
    "#downsample\n",
    "target_ratio=0.5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "scores = []\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "for fold, (train_idx, test_idx) in enumerate(skf.split(dataset, labels)):\n",
    "    print(f\"Fold {fold+1}/{n_splits}--------------------------\")\n",
    "\n",
    "    # Split train and test sets\n",
    "    X_train, X_test = dataset.iloc[train_idx], dataset.iloc[test_idx]\n",
    "    y_train, y_test = labels.iloc[train_idx], labels.iloc[test_idx]\n",
    "    \n",
    "    # Perform weighted downsampling on training data\n",
    "    X_train_balanced, y_train_balanced = weighted_downsample_LABELS(X_train, y_train, target_ratio = 0.3)\n",
    "    print(\"Training Fold Label Distr:\", dict(pd.Series(y_train_balanced).value_counts()))\n",
    "\n",
    "    #get frax after downsample\n",
    "    frax_score_train, frax_score_test = X_train_balanced[\"FRAX_SCORE\"], X_test[\"FRAX_SCORE\"]\n",
    "    X_train_balanced, X_test = X_train_balanced.drop(columns = [\"FRAX_SCORE\"]), X_test.drop(columns = [\"FRAX_SCORE\"])\n",
    "\n",
    "    if random_cv_avail == True:\n",
    "        random_search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=20, cv=5, scoring='accuracy', n_jobs=-1, random_state=42)\n",
    "        random_search.fit(X_train_balanced, y_train_balanced)\n",
    "        print(\"Best Parameters:\", random_search.best_params_)\n",
    "        model = random_search.best_estimator_\n",
    "\n",
    "    eval_run(model, X_train_balanced, y_train_balanced, descr = \"MODEL Train:)\n",
    "    FRAX_threshold = eval_frax(frax_score_train, y_train_balanced, descr = \"FRAX Train:\")\n",
    "    \n",
    "    # Evaluate on the original test set (without downsampling)\n",
    "    eval_run(model, X_test, y_test, descr = \"MODEL Test:\")\n",
    "    eval_frax(frax_score_test, y_test, descr = \"FRAX Test:\", threshold = FRAX_threshold)\n",
    "\n",
    "    print(\"Test Fold Label Distr:\", dict(pd.Series(y_test).value_counts()))\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4375998-a7cc-4742-a572-8288c3168b01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
